#MrunmaiMagar-CSE6363-007-Assignment2
# -*- coding: utf-8 -*-
"""ensemble_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_fRks5B_Of4m35scnD7Wl35cVMz22tiB
"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,AdaBoostClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import load_iris

def ensemble_learning(X, y, task='classification'):
    """
    Implement ensemble learning methods: Decision Trees, Bagging, Random Forest, and Boosting.
    Parameters:
    - X: Input features (numpy array or pandas DataFrame)
    - y: Target variable (numpy array or pandas Series)
    - task: Type of task, either 'classification' or 'regression' (default: 'classification')
    Returns:
    - results: Dictionary containing evaluation results for each ensemble method
"""
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)

    # Initialize results dictionary
    results = {}

    # Decision Tree
    dt_classifier = DecisionTreeClassifier(random_state=42)
    # Train the Decision Tree classifier on the training data
    dt_classifier.fit(X_train, y_train) 
    # Predict the labels for the testing data
    dt_pred = dt_classifier.predict(X_test) 
    # Calculate the accuracy of the Decision Tree classifier
    dt_acc = accuracy_score(y_test, dt_pred)
    # Store the accuracy in the results dictionary
    results['Decision Tree'] = dt_acc 

    # Bagging
    bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(),n_estimators=2, random_state=42)
    # Train the Bagging classifier on the training data
    bagging_classifier.fit(X_train, y_train)
    # Predict the labels for the testing data
    bagging_pred = bagging_classifier.predict(X_test)
    # Calculate the accuracy of the Bagging classifier
    bagging_acc = accuracy_score(y_test, bagging_pred) 
    # Store the accuracy in the results dictionary
    results['Bagging'] = bagging_acc

    # Random Forest
    rf_classifier = RandomForestClassifier(n_estimators=2, random_state=42)
    # Train the Random Forest classifier on the training data
    rf_classifier.fit(X_train, y_train) 
    # Predict the labels for the testing data
    rf_pred = rf_classifier.predict(X_test) 
    # Calculate the accuracy of the Random Forest classifier
    rf_acc = accuracy_score(y_test, rf_pred)
    # Store the accuracy in the results dictionary
    results['Random Forest'] = rf_acc 

    # Boosting
    if task == 'classification':
        boosting_classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=2,random_state=42)
        # Train the Boosting classifier
        boosting_classifier.fit(X_train, y_train)  
        # Make predictions on test data
        y_prediction = boosting_classifier.predict(X_test)  
        # Calculate accuracy
        accuracy_boosting = accuracy_score(y_test, y_prediction)  
        # Store accuracy in results dictionary
        results['Boosting'] = accuracy_boosting  

    else: # If task is regression
    # For regression tasks, you can use GradientBoostingRegressor instead
    # pass
    # Train the Boosting classifier on the training data
        boosting_regressor = GradientBoostingRegressor(n_estimators=2, random_state=42)
        boosting_regressor.fit(X_train, y_train)

        # Predict the labels for the testing data
        y_prediction = boosting_regressor.predict(X_test)

        # Calculate the accuracy of the Boosting classifier
        mse_boosting = mean_squared_error(y_test, y_prediction)

        # Store the accuracy in the results dictionary
        results['Boosting'] = mse_boosting

    return results

# Example usage:
iris = load_iris()
X = iris.data
y = iris.target
results = ensemble_learning(X, y, task='classification')
print(results)
